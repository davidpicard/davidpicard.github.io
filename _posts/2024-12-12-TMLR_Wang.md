---
layout: post
title: "An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning"
categories: publications
authors: Xi Wang, Nicolas Dufour, Nefeli Andreou, Marie-Paule Cani, Victoria Fernandez Abrevaya, David Picard, Vicky Kalogeiton
venue: "TMLR"
arxiv: https://arxiv.org/abs/2404.13040
image: /images/cfg.png
---
Classifier-Free Guidance (CFG) enhances the quality and condition adherence of text-to-image diffusion models. Recent works vary the weights throughout the diffusion process, reporting superior results but without providing any rationale or analysis. By conducting comprehensive experiments, this paper provides insights into CFG weight schedulers. Our findings suggest that simple, monotonically increasing weight schedulers consistently lead to improved performances. In addition, more complex parametrized schedulers can be optimized for further improvement, but do not generalize across different models and tasks.
